<Type Name="SpeechRecognizer" FullName="System.Speech.Recognition.SpeechRecognizer">
  <Metadata><Meta Name="ms.openlocfilehash" Value="03a2ecf66a486d776bd07181a5aa2607aa7004ff" /><Meta Name="ms.sourcegitcommit" Value="055a4a82a0b08bfbdc21bd1347fb71f7fe2c099e" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="zh-CN" /><Meta Name="ms.lasthandoff" Value="08/15/2019" /><Meta Name="ms.locfileid" Value="69258127" /></Metadata><TypeSignature Language="C#" Value="public class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechRecognizer extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizer&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="F#" Value="type SpeechRecognizer = class&#xA;    interface IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary>提供对在 Windows 桌面上可用的共享语言识别服务的访问。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 应用程序使用共享识别器来访问 Windows 语音识别。 <xref:System.Speech.Recognition.SpeechRecognizer>使用对象添加到 Windows 语音用户体验。  
  
 此类可用于控制语音识别过程的各个方面:  
  
-   若要管理语音识别语法, 请<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>、、和<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>。  
  
-   若要获取有关当前语音识别操作的信息, 请<xref:System.Speech.Recognition.SpeechRecognizer>订阅<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>的<xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>、和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。  
  
-   若要查看或修改识别器返回的备用结果数, 请使用<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>属性。 识别器将识别结果<xref:System.Speech.Recognition.RecognitionResult>返回对象。  
  
-   若要访问或监视共享识别器的状态, 请使用<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>、、 <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>、和属性, 并使用、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>和<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件。  
  
-   若要同步对识别器所做的<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>更改, 请使用方法。 共享识别器使用多个线程来执行任务。  
  
-   若要模拟共享识别器的输入, 请<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>使用<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>和方法。  
  
 Windows 语音识别的配置是通过使用**控制面板**中的 "**语音属性**" 对话框来管理的。 此接口用于选择默认的桌面语音识别引擎和语言、音频输入设备以及语音识别的睡眠行为。 如果在应用程序运行时更改了 Windows 语音识别的配置, (例如, 如果禁用了语音识别或更改了输入语言), 则更改将影响所有<xref:System.Speech.Recognition.SpeechRecognizer>对象。  
  
 若要创建独立于 Windows 语音识别的进程内语音识别器, 请使用<xref:System.Speech.Recognition.SpeechRecognitionEngine>类。  
  
> [!NOTE]
>  在释放<xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A>对语音识别器的最后一个引用之前, 始终调用。 否则, 在垃圾回收器调用识别器对象的`Finalize`方法之前, 不会释放它所使用的资源。  
  
   
  
## Examples  
 下面的示例是一个控制台应用程序的一部分, 该应用程序加载语音识别语法并演示异步仿真输入、关联的识别结果和语音识别器引发的相关事件。  如果 Windows 语音识别未运行, 则启动此应用程序也将启动 Windows 语音识别。 如果 Windows 语音识别处于**睡眠**状态, 则<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>始终返回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="T:System.Speech.Recognition.Grammar" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognizer();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>初始化 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 类的新实例。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 每<xref:System.Speech.Recognition.SpeechRecognizer>个对象维护一组单独的语音识别语法。  
  
   
  
## Examples  
 下面的示例是一个控制台应用程序的一部分, 该应用程序加载语音识别语法并演示异步仿真输入、关联的识别结果和语音识别器引发的相关事件。 如果 Windows 语音识别未运行, 则启动此应用程序也将启动 Windows 语音识别。 如果 Windows 语音识别处于**睡眠**状态, 则<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>始终返回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
    <Member MemberName="AudioFormat">
      <MemberSignature Language="C#" Value="public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioFormat As SpeechAudioFormatInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::AudioFormat::SpeechAudioFormatInfo ^ AudioFormat { System::Speech::AudioFormat::SpeechAudioFormatInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioFormat : System.Speech.AudioFormat.SpeechAudioFormatInfo" Usage="System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.AudioFormat.SpeechAudioFormatInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取语音识别器接收的音频格式。</summary>
        <value>语音识别器的音频输入的格式或 <see langword="null" /> ，如果识别器输入未配置。</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioLevel">
      <MemberSignature Language="C#" Value="public int AudioLevel { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 AudioLevel" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioLevel As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int AudioLevel { int get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioLevel : int" Usage="System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取语音识别器接收的音频级别。</summary>
        <value>输入的音频级别到语音识别器，从 0 到 100。</value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      </Docs>
    </Member>
    <Member MemberName="AudioLevelUpdated">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioLevelUpdated As EventHandler(Of AudioLevelUpdatedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioLevelUpdatedEventArgs ^&gt; ^ AudioLevelUpdated;" />
      <MemberSignature Language="F#" Value="member this.AudioLevelUpdated : EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " Usage="member this.AudioLevelUpdated : System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当共享识别器报告其音频输入的级别时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 识别器每秒多次引发此事件。 引发事件的频率取决于运行应用程序的计算机。  
  
 若要在事件发生时获取音频级别, 请使用<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>关联<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>的的属性。 若要获取识别器的当前音频级别, 请使用识别器的<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>属性。  
  
 为`AudioLevelUpdated`事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例将`AudioLevelUpdated`事件的处理程序添加<xref:System.Speech.Recognition.SpeechRecognizer>到对象。 处理程序将新的音频级别输出到控制台。  
  
```csharp  
private SpeechRecognizer recognizer;  
  
// Initialize the SpeechRecognizer object.   
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add an event handler for the AudioLevelUpdated event.  
  recognizer.AudioLevelUpdated +=   
    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  
  
  // Add other initialization code here.  
  
}  
  
// Write the audio level to the console when the AudioLevelUpdated event is raised.  
void recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  
{  
  Console.WriteLine("The audio level is now: {0}.", e.AudioLevel);  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioLevelUpdatedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      </Docs>
    </Member>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取音频流中的当前位置，此音频流由向语音识别器提供输入的设备产生。</summary>
        <value>它接收输入一个识别器的音频输入流中的当前位置。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 共享识别器在运行桌面语音识别时接收输入。  
  
 `AudioPosition`属性引用输入设备在其生成的音频流中的位置。 与此<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>相反, 属性在处理音频输入中引用识别器的位置。 这些位置可能不同。  例如, 如果识别器收到了尚未生成识别结果的输入, 则该<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>属性的值小于<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>属性的值。  
  
   
  
## Examples  
 在下面的示例中, 共享语音识别器使用听写语法来匹配语音输入。 当语音识别器<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>在其输入时检测到语音<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>时, <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>事件的处理程序会将<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>、和写入控制台。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add handlers for events.  
      recognizer.LoadGrammarCompleted +=   
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
      recognizer.SpeechRecognized +=   
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
      recognizer.SpeechDetected +=   
        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
  
      // Create a dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load the grammar object to the recognizer.  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Gather information about detected speech and write it to the console.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Speech detected:");  
      Console.WriteLine("  Audio level: " + recognizer.AudioLevel);  
      Console.WriteLine("  Audio position: " + recognizer.AudioPosition);  
      Console.WriteLine("  Recognizer audio position: " + recognizer.RecognizerAudioPosition);  
    }  
  
    // Write the text of the recognition result to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {   
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Write the name of the loaded grammar to the console.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="AudioSignalProblemOccurred">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioSignalProblemOccurred As EventHandler(Of AudioSignalProblemOccurredEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioSignalProblemOccurredEventArgs ^&gt; ^ AudioSignalProblemOccurred;" />
      <MemberSignature Language="F#" Value="member this.AudioSignalProblemOccurred : EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " Usage="member this.AudioSignalProblemOccurred : System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当识别器在音频信号中遇到问题时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 若要获取发生的问题, 请<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>使用关联<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>的的属性。  
  
 为`AudioSignalProblemOccurred`事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例定义了一个事件处理程序, 用于收集`AudioSignalProblemOccurred`有关事件的信息。  
  
```  
private SpeechRecognizer recognizer;  
  
// Initialize the speech recognition engine.  
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add a handler for the AudioSignalProblemOccurred event.  
  recognizer.AudioSignalProblemOccurred +=   
    new EventHandler<AudioSignalProblemOccurredEventArgs>(  
      recognizer_AudioSignalProblemOccurred);  
}  
  
// Gather information when the AudioSignalProblemOccurred event is raised.  
void recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  
{  
  StringBuilder details = new StringBuilder();  
  
  details.AppendLine("Audio signal problem information:");  
  details.AppendFormat(  
    " Audio level:               {0}" + Environment.NewLine +  
    " Audio position:            {1}" + Environment.NewLine +  
    " Audio signal problem:      {2}" + Environment.NewLine +  
    " Recognition engine audio position: {3}" + Environment.NewLine,  
    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  
    e.recoEngineAudioPosition);  
  
  // Insert additional event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblem" />
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="AudioState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioState AudioState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioState AudioState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioState As AudioState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioState AudioState { System::Speech::Recognition::AudioState get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioState : System.Speech.Recognition.AudioState" Usage="System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取语音识别器接收的状态音频。</summary>
        <value>语音识别器处理的音频输入的状态。</value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      </Docs>
    </Member>
    <Member MemberName="AudioStateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioStateChanged As EventHandler(Of AudioStateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioStateChangedEventArgs ^&gt; ^ AudioStateChanged;" />
      <MemberSignature Language="F#" Value="member this.AudioStateChanged : EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " Usage="member this.AudioStateChanged : System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当音频中的状态更改正被识别器接收时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 若要获取事件时的音频状态, 请使用<xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>关联<xref:System.Speech.Recognition.AudioStateChangedEventArgs>的的属性。 若要获取识别器的当前音频状态, 请使用识别器的<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>属性。 有关音频状态的详细信息, 请参阅<xref:System.Speech.Recognition.AudioState>枚举。  
  
 为`AudioStateChanged`事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例使用`AudioStateChanged`事件的处理程序, 在每次<xref:System.Speech.Recognition.AudioState>使用枚举的<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>成员进行更改时将识别器的新写入控制台。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Create and load a grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the AudioStateChanged event.  
    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("The new audio state is: " + e.AudioState);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine();  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
        Console.WriteLine();  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Done.");  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the recognizer into Listening mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        Console.WriteLine();  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
        <altmember cref="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      </Docs>
    </Member>
    <MemberGroup MemberName="Dispose">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>处置此 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 对象。</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberSignature Language="F#" Value="abstract member Dispose : unit -&gt; unit&#xA;override this.Dispose : unit -&gt; unit" Usage="speechRecognizer.Dispose " />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>处置此 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 对象。</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected virtual void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig newslot virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overridable Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="C++ CLI" Value="protected:&#xA; virtual void Dispose(bool disposing);" />
      <MemberSignature Language="F#" Value="abstract member Dispose : bool -&gt; unit&#xA;override this.Dispose : bool -&gt; unit" Usage="speechRecognizer.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing"><see langword="true" /> 表示释放托管资源和非托管资源；<see langword="false" /> 表示仅释放非托管资源。</param>
        <summary>处置 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 对象并释放会话期间使用的资源。</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognize">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>使用文本而不是同步语音识别的音频来模拟输入到共享语音识别器。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 这些方法不使用系统音频输入。 这在测试或调试应用程序或语法时非常有用。  
  
> [!NOTE]
>  如果 Windows 语音识别处于**休眠**状态, 则这些方法将返回`null`。  
  
 共享识别器会引发<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件, 就好像未模拟识别操作一样。 识别器忽略新行和额外的空格, 并将标点符号视为文本输入。  
  
> [!NOTE]
>  共享识别器为响应仿真输入而生成的`null` <xref:System.Speech.Recognition.RecognitionResult.Audio%2A>对象的属性值为。 <xref:System.Speech.Recognition.RecognitionResult>  
  
 若要模拟异步识别, 请<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>使用方法。  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function EmulateRecognize (inputText As String) As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">标识操作的输入。</param>
        <summary>使用文本而不是异步语音识别的音频来模拟输入短语到共享语音识别器。</summary>
        <returns>识别操作的识别结果；或者，如果操作不成功或是窗口语音识别处于“睡眠”状态，则为 <see langword="null" />。</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 向输入短语应用语法规则时, Vista 和 Windows 7 附带的识别器忽略大小写和字符宽度。 有关此类比较的详细信息, 请参阅<xref:System.Globalization.CompareOptions>枚举值<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>和<xref:System.Globalization.CompareOptions.IgnoreWidth>。 识别器还会忽略新行和额外的空格, 并将标点符号视为文本输入。  
  
   
  
## Examples  
 下面的示例将示例语法加载到共享识别器并模拟到识别器的输入。 如果 Windows 语音识别未运行, 则启动此应用程序也将启动 Windows 语音识别。 如果 Windows 语音识别处于**睡眠**状态, 则<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>始终返回 null。  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        RecognitionResult result;  
  
        // This EmulateRecognize call matches the grammar and returns a  
        // recognition result.  
        result = recognizer.EmulateRecognize("testing testing");  
        OutputResult(result);  
  
        // This EmulateRecognize call does not match the grammar and   
        // returns null.  
        result = recognizer.EmulateRecognize("testing one two three");  
        OutputResult(result);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Output information about a recognition result to the console.  
    private static void OutputResult(RecognitionResult result)  
    {  
      if (result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">词单元数组，包含识别操作输入。</param>
        <param name="compareOptions">描述用于模拟识别操作的比较说明类型的枚举值的按位组合。</param>
        <summary>使用文本代替同步语音识别的音频来模拟特定字输入到共享语音识别器，并指定识别器如何处理单词和加载的语音识别语法间的 Unicode 比较。</summary>
        <returns>识别操作的识别结果；或者，如果操作不成功或是窗口语音识别处于“睡眠”状态，则为 <see langword="null" />。</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 此方法使用`wordUnits`参数<xref:System.Speech.Recognition.RecognitionResult>中提供的信息创建对象。  
  
 `compareOptions`当识别器将语法规则应用于输入短语时, 将使用。 如果<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 或<xref:System.Globalization.CompareOptions.IgnoreCase>值存在, 则 Vista 和 Windows 7 附带的识别器会忽略大小写。 识别器始终忽略字符宽度并从不忽略假名类型。 识别器还会忽略新行和额外的空格, 并将标点符号视为文本输入。 有关字符宽度和假名类型的详细信息, 请参阅<xref:System.Globalization.CompareOptions>枚举。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">标识操作的输入相。</param>
        <param name="compareOptions">描述用于模拟识别操作的比较说明类型的枚举值的按位组合。</param>
        <summary>使用文本代替异步语音识别的音频来模拟短语输入到共享语音识别器，并指定识别器如何处理短语和加载的语音识别语法间的 Unicode 比较。</summary>
        <returns>识别操作的识别结果；或者，如果操作不成功或是窗口语音识别处于“睡眠”状态，则为 <see langword="null" />。</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `compareOptions`当识别器将语法规则应用于输入短语时, 将使用。 如果<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 或<xref:System.Globalization.CompareOptions.IgnoreCase>值存在, 则 Vista 和 Windows 7 附带的识别器会忽略大小写。 识别器始终忽略字符宽度并从不忽略假名类型。 识别器还会忽略新行和额外的空格, 并将标点符号视为文本输入。 有关字符宽度和假名类型的详细信息, 请参阅<xref:System.Globalization.CompareOptions>枚举。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognizeAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>使用文本而不是异步语音识别的音频来模拟输入到共享语音识别器。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 这些方法不使用系统音频输入。 这在测试或调试应用程序或语法时非常有用。  
  
 共享识别器会引发<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件, 就好像未模拟识别操作一样。 当识别器完成异步识别操作时, 它会引发<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>事件。 识别器忽略新行和额外的空格, 并将标点符号视为文本输入。  
  
> [!NOTE]
>  如果 Windows 语音识别处于**睡眠**状态, 则共享识别器不处理输入, 也不会引发<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>和相关事件, <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>但仍会引发事件。  
  
> [!NOTE]
>  共享识别器为响应仿真输入而生成的`null` <xref:System.Speech.Recognition.RecognitionResult.Audio%2A>对象的属性值为。 <xref:System.Speech.Recognition.RecognitionResult>  
  
 若要模拟同步识别, 请<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>使用方法。  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub EmulateRecognizeAsync (inputText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">标识操作的输入。</param>
        <summary>使用文本而不是异步语音识别的音频来模拟输入短语到共享语音识别器。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 向输入短语应用语法规则时, Vista 和 Windows 7 附带的识别器忽略大小写和字符宽度。 有关此类比较的详细信息, 请参阅<xref:System.Globalization.CompareOptions>枚举值<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>和<xref:System.Globalization.CompareOptions.IgnoreWidth>。 识别器还会忽略新行和额外的空格, 并将标点符号视为文本输入。  
  
   
  
## Examples  
 下面的示例是一个控制台应用程序的一部分, 该应用程序加载语音识别语法并演示异步仿真输入、关联的识别结果和语音识别器引发的相关事件。 如果 Windows 语音识别未运行, 则启动此应用程序也将启动 Windows 语音识别。 如果 Windows 语音识别处于**睡眠**状态, 则<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>始终返回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">词单元数组，包含识别操作输入。</param>
        <param name="compareOptions">描述用于模拟识别操作的比较说明类型的枚举值的按位组合。</param>
        <summary>使用文本代替异步语音识别的音频来模拟特定字输入到共享语音识别器，并指定识别器如何处理单词和加载的语音识别语法间的 Unicode 比较。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 此方法使用`wordUnits`参数<xref:System.Speech.Recognition.RecognitionResult>中提供的信息创建对象。  
  
 `compareOptions`当识别器将语法规则应用于输入短语时, 将使用。 如果<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 或<xref:System.Globalization.CompareOptions.IgnoreCase>值存在, 则 Vista 和 Windows 7 附带的识别器会忽略大小写。 识别器始终忽略字符宽度并从不忽略假名类型。 识别器还会忽略新行和额外的空格, 并将标点符号视为文本输入。 有关字符宽度和假名类型的详细信息, 请参阅<xref:System.Globalization.CompareOptions>枚举。  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">标识操作的输入相。</param>
        <param name="compareOptions">描述用于模拟识别操作的比较说明类型的枚举值的按位组合。</param>
        <summary>使用文本代替异步语音识别的音频来模拟短语输入到共享语音识别器，并指定识别器如何处理短语和加载的语音识别语法间的 Unicode 比较。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `compareOptions`当识别器将语法规则应用于输入短语时, 将使用。 如果<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> 或<xref:System.Globalization.CompareOptions.IgnoreCase>值存在, 则 Vista 和 Windows 7 附带的识别器会忽略大小写。 识别器始终忽略字符宽度并从不忽略假名类型。 识别器还会忽略新行和额外的空格, 并将标点符号视为文本输入。 有关字符宽度和假名类型的详细信息, 请参阅<xref:System.Globalization.CompareOptions>枚举。  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event EmulateRecognizeCompleted As EventHandler(Of EmulateRecognizeCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::EmulateRecognizeCompletedEventArgs ^&gt; ^ EmulateRecognizeCompleted;" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeCompleted : EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " Usage="member this.EmulateRecognizeCompleted : System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当共享的识别器终结模拟输入的异步识别操作时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 每<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>个方法开始一个异步标识操作。 识别器在完成`EmulateRecognizeCompleted`异步操作时引发事件。  
  
 异步识别操作可以<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>引发、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>事件是识别器针对给定操作引发的最后一个此类事件。  
  
 为`EmulateRecognizeCompleted`事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例是一个控制台应用程序的一部分, 该应用程序加载语音识别语法并演示异步仿真输入、关联的识别结果和语音识别器引发的相关事件。 如果 Windows 语音识别未运行, 则启动此应用程序也将启动 Windows 语音识别。 如果 Windows 语音识别处于**睡眠**模式, 则<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>始终返回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=   
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar  
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="Enabled">
      <MemberSignature Language="C#" Value="public bool Enabled { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool Enabled" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberSignature Language="VB.NET" Value="Public Property Enabled As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool Enabled { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.Enabled : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取或设置一个值，该值指示此 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 对象是否准备好处理语音。</summary>
        <value><see langword="true" /> 如果此 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 对象执行语音识别；否则<see langword="false" />。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 对此属性的更改不会影响<xref:System.Speech.Recognition.SpeechRecognizer>类的其他实例。  
  
 默认情况下, <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> `true`属性的值针对的是新实例化的实例<xref:System.Speech.Recognition.SpeechRecognizer>。 当识别器禁用时, 识别器的语音识别语法均不能用于识别操作。 设置识别器的<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>属性不会影响识别器的<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>属性。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      </Docs>
    </Member>
    <Member MemberName="Grammars">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt; Grammars { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.Grammar&gt; Grammars" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammars As ReadOnlyCollection(Of Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ Grammars { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammars : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;" Usage="System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取在此 <see cref="T:System.Speech.Recognition.Grammar" /> 实例中加载的 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 对象的集合。</summary>
        <value>应用程序加载到共享识别器的当前实例的 <see cref="T:System.Speech.Recognition.Grammar" /> 对象的集合。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 此属性不返回由其他应用程序加载的任何语音识别语法。  
  
   
  
## Examples  
 下面的示例将信息输出到控制台, 以便将每个语音识别语法加载到共享语音识别器。  
  
```csharp  
  
using System;  
using System.Collections.Generic;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Grammar sampleGrammar = new Grammar(new GrammarBuilder("sample phrase"));  
        sampleGrammar.Name = "Sample Grammar";  
        recognizer.LoadGrammar(sampleGrammar);  
  
        OutputGrammarList(recognizer);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void OutputGrammarList(SpeechRecognizer recognizer)  
    {  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      if (grammars.Count > 0)  
      {  
        Console.WriteLine("Loaded grammars:");  
        foreach (Grammar g in grammars)  
        {  
          Console.WriteLine("  Grammar: {0}",  
            (g.Name != null) ? g.Name : "<no name>");  
        }  
      }  
      else  
      {  
        Console.WriteLine("No grammars loaded.");  
      }  
    }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammar">
      <MemberSignature Language="C#" Value="public void LoadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">加载语音识别语法。</param>
        <summary>加载语音识别语法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果语音识别语法已加载、正在异步加载或者未能加载到任何识别器, 共享识别器将引发异常。 如果识别器正在运行, 则应用程序<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>必须使用在加载、卸载、启用或禁用语法之前暂停语音识别引擎。  
  
 若要以异步方式加载语音识别语法, <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>请使用方法。  
  
   
  
## Examples  
 下面的示例是一个控制台应用程序的一部分, 该应用程序加载语音识别语法并演示异步仿真输入、关联的识别结果和语音识别器引发的相关事件。 如果 Windows 语音识别未运行, 则启动此应用程序也将启动 Windows 语音识别。 如果 Windows 语音识别处于**睡眠**状态, 则<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>始终返回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }   
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarAsync">
      <MemberSignature Language="C#" Value="public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammarAsync(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammarAsync(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarAsync : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammarAsync grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">加载语音识别语法。</param>
        <summary>异步加载语音识别语法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 当识别器完成此异步操作时, 它将<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>引发一个事件。 如果语音识别语法已加载、正在异步加载或者未能加载到任何识别器, 识别器会引发异常。 如果识别器正在运行, 则应用程序<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>必须使用在加载、卸载、启用或禁用语法之前暂停语音识别引擎。  
  
 若要同步加载语音识别语法, 请使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event LoadGrammarCompleted As EventHandler(Of LoadGrammarCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::LoadGrammarCompletedEventArgs ^&gt; ^ LoadGrammarCompleted;" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarCompleted : EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " Usage="member this.LoadGrammarCompleted : System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当识别器完成语音识别语法的异步加载时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 识别器的<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>方法启动异步操作。 识别器在完成`LoadGrammarCompleted`操作后引发事件。 若要获取<xref:System.Speech.Recognition.Grammar>识别器加载的对象, 请<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>使用关联<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>的的属性。 若要获取识别<xref:System.Speech.Recognition.Grammar>器已加载的当前对象, 请使用识别<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>器的属性。  
  
 为`LoadGrammarCompleted`事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例创建一个共享语音识别器, 然后创建两种类型的语法来识别特定单词并接受免费听写。 该示例将所有创建的语法异步加载到识别器。 识别器的<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件的处理程序将分别向控制台写入用于执行识别的语法的名称和识别结果的文本。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Add a handler for the StateChanged event.  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Create "yesno" grammar.  
        Choices yesChoices = new Choices(new string[] { "yes", "yup", "yeah}" });  
        SemanticResultValue yesValue =  
            new SemanticResultValue(yesChoices, (bool)true);  
        Choices noChoices = new Choices(new string[] { "no", "nope", "neah" });  
        SemanticResultValue noValue =  
            new SemanticResultValue(noChoices, (bool)false);  
        SemanticResultKey yesNoKey =  
            new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
        Grammar yesnoGrammar = new Grammar(yesNoKey);  
        yesnoGrammar.Name = "yesNo";  
  
        // Create "done" grammar.  
        Grammar doneGrammar =  
          new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
        doneGrammar.Name = "Done";  
  
        // Create dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation";  
  
        // Load grammars to the recognizer.  
        recognizer.LoadGrammarAsync(yesnoGrammar);  
        recognizer.LoadGrammarAsync(doneGrammar);  
        recognizer.LoadGrammarAsync(dictation);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  
    // Put the shared speech recognizer into "listening" mode.   
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.LoadGrammarCompletedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="MaxAlternates">
      <MemberSignature Language="C#" Value="public int MaxAlternates { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 MaxAlternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxAlternates As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int MaxAlternates { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.MaxAlternates : int with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取或设置共享识别器为每个识别操作返回的备用识别结果的最大数量。</summary>
        <value>语音识别器返回每个标识操作的替换结果的最大数目。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 类的<xref:System.Speech.Recognition.RecognitionResult>属性包含对象的集合, 这些对象表示输入的其他候选项解释。 <xref:System.Speech.Recognition.RecognizedPhrase> <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>  
  
 的默认值<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>为10。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="PauseRecognizerOnRecognition">
      <MemberSignature Language="C#" Value="public bool PauseRecognizerOnRecognition { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool PauseRecognizerOnRecognition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberSignature Language="VB.NET" Value="Public Property PauseRecognizerOnRecognition As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool PauseRecognizerOnRecognition { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.PauseRecognizerOnRecognition : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取或设置一个值，此值指示共享识别器是否在应用程序处理 <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> 事件时暂停识别操作。</summary>
        <value><see langword="true" /> 如果共享识别器等待处理输入，当所有应用程序处理 <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> 事件时；否则<see langword="false" />。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 将此属性设置`true`为, 如果在<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>事件处理程序中, 你的应用程序需要更改语音识别服务的状态, 或者在语音识别服务之前更改已加载或已启用的语音识别语法处理更多输入。  
  
> [!NOTE]
>  将属性设置为`true`会导致<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>每个应用程序中的每个事件处理程序阻止 Windows 语音识别服务。 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>  
  
 若要将共享识别器的更改与应用程序状态同步, 请<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>使用方法。  
  
 如果<xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>为`true`, 则在执行处理程序的过程中, 语音识别服务会在新的音频输入到达时暂停和缓冲。 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>事件处理程序退出后, 语音识别服务将恢复识别并从其输入缓冲区开始处理信息。  
  
 若要启用或禁用语音识别服务, 请使用<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>属性。  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerAudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan RecognizerAudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan RecognizerAudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerAudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan RecognizerAudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerAudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取在处理的音频输入中的识别器当前位置。</summary>
        <value>识别器的位置在处理音频的输入。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `RecognizerAudioPosition`属性引用识别器在处理其音频输入时的位置。 与此相反, <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>该属性将引用输入设备在其生成的音频流中的位置。 这些位置可能不同。 例如, 如果识别器收到了尚未生成识别结果的输入, 则该<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>属性的值小于<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>属性的值。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerInfo">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizerInfo RecognizerInfo" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerInfo As RecognizerInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerInfo ^ RecognizerInfo { System::Speech::Recognition::RecognizerInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerInfo : System.Speech.Recognition.RecognizerInfo" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取共享语音识别器的相关信息。</summary>
        <value>该共享语音识别器的相关信息。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 此属性返回 Windows 语音识别所使用的语音识别器的相关信息。  
  
   
  
## Examples  
 下面的示例将有关共享识别器的信息发送到控制台。  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Console.WriteLine("Recognizer information for the shared recognizer:");  
        Console.WriteLine("  Name: {0}", recognizer.RecognizerInfo.Name);  
        Console.WriteLine("  Culture: {0}", recognizer.RecognizerInfo.Culture.ToString());  
        Console.WriteLine("  Description: {0}", recognizer.RecognizerInfo.Description);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerInfo" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerUpdateReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      <MemberSignature Language="VB.NET" Value="Public Event RecognizerUpdateReached As EventHandler(Of RecognizerUpdateReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::RecognizerUpdateReachedEventArgs ^&gt; ^ RecognizerUpdateReached;" />
      <MemberSignature Language="F#" Value="member this.RecognizerUpdateReached : EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " Usage="member this.RecognizerUpdateReached : System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当识别器暂停以同步识别和其他操作时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 在修改其<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> <xref:System.Speech.Recognition.SpeechRecognizer> 对象之前,应用程序必须使用暂停正在<xref:System.Speech.Recognition.Grammar>运行的实例。 例如, 当暂停时<xref:System.Speech.Recognition.SpeechRecognizer> , 可以加载、卸载、启用和禁用<xref:System.Speech.Recognition.Grammar>对象。 当<xref:System.Speech.Recognition.SpeechRecognizer>已准备好接受修改时, 将引发此事件。  
  
 为<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例演示了一个加载和卸载<xref:System.Speech.Recognition.Grammar>对象的控制台应用程序。 应用程序使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法请求语音识别引擎暂停, 使其可以接收更新。 然后, 应用程序将加载或<xref:System.Speech.Recognition.Grammar>卸载对象。  
  
 在每次更新时, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件处理程序会将当前加载<xref:System.Speech.Recognition.Grammar>的对象的名称和状态写入控制台。 加载和卸载语法时, 应用程序首先识别场动物的名称, 然后识别场动物的名称和水果的名称, 然后仅识别水果的名称。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
      </Docs>
    </Member>
    <MemberGroup MemberName="RequestRecognizerUpdate">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>请求共享识别器暂停和更新其状态。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 使用此方法将更改同步到共享识别器。 例如, 如果在识别器正在处理输入时加载或卸载语音识别语法, 请使用此方法和<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件, 将应用程序行为与识别器的状态进行同步。  
  
 调用此方法时, 识别器将暂停或完成异步操作并生成一个<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件。 然后<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> , 事件处理程序可以在识别操作之间修改识别器的状态。  
  
 调用此方法时:  
  
-   如果识别器未处理输入, 则识别器会立即生成<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件。  
  
-   如果识别器正在处理由无声或背景噪音组成的输入, 识别器将暂停识别操作并生成<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件。  
  
-   如果识别器正在处理的输入不包括无声或背景干扰, 则识别器完成识别操作, 然后生成<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件。  
  
 识别器处理<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件时:  
  
-   识别器不处理输入, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>属性的值保持不变。  
  
-   识别器继续收集输入, <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>属性的值可以更改。  
  
 若要更改共享识别器在应用程序处理<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件时是否暂停识别操作, 请<xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>使用属性。  
  
   
  
## Examples  
 下面的示例演示了一个加载和卸载<xref:System.Speech.Recognition.Grammar>对象的控制台应用程序。 应用程序使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法请求语音识别引擎暂停, 使其可以接收更新。 然后, 应用程序将加载或<xref:System.Speech.Recognition.Grammar>卸载对象。  
  
 在每次更新时, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件处理程序会将当前加载<xref:System.Speech.Recognition.Grammar>的对象的名称和状态写入控制台。 加载和卸载语法时, 应用程序首先识别场动物的名称, 然后识别场动物的名称和水果的名称, 然后仅识别水果的名称。  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
  
      // Check to see if recognizer is loaded, wait if it is not loaded.  
      if (recognizer.State != RecognizerState.Listening)  
      {  
        Thread.Sleep(5000);  
  
        // Put recognizer in listening state.  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      // At the update, get the names and enabled status of the currently loaded grammars.  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      </Docs>
    </MemberGroup>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate();" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : unit -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>请求共享识别器暂停和更新其状态。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 当<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>识别器生成事件时<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> , 的<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>属性为`null`。  
  
 若要提供用户令牌, 请使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>或<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。 若要指定音频位置偏移量, 请<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>使用方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate userToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
      </Parameters>
      <Docs>
        <param name="userToken">用户定义信息包含该操作的信息。</param>
        <summary>请求共享识别器暂停和更新其状态并为关联的事件提供用户标记。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 当<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>识别器生成事件时<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> , 的属性将<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>包含`userToken`参数的值。  
  
 若要指定音频位置偏移量, 请<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>使用方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken, valuetype System.TimeSpan audioPositionAheadToRaiseUpdate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object, audioPositionAheadToRaiseUpdate As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj * TimeSpan -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate (userToken, audioPositionAheadToRaiseUpdate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
        <Parameter Name="audioPositionAheadToRaiseUpdate" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="userToken">用户定义信息包含该操作的信息。</param>
        <param name="audioPositionAheadToRaiseUpdate">从当前到延迟请求的 <see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /> 偏移量。</param>
        <summary>请求共享识别器暂停和更新其状态并为关联的事件提供偏移量和用户标记。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 在识别器的<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>等于当前<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>的`audioPositionAheadToRaiseUpdate`和参数的值之前, 识别器不会启动识别器更新请求。  
  
 当<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>识别器生成事件时<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> , 的属性将<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>包含`userToken`参数的值。  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechDetected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechDetected As EventHandler(Of SpeechDetectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechDetectedEventArgs ^&gt; ^ SpeechDetected;" />
      <MemberSignature Language="F#" Value="member this.SpeechDetected : EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " Usage="member this.SpeechDetected : System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当识别器删除它可以标识为语音的输入时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 共享识别器可以引发此事件以响应输入。 <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> 关联<xref:System.Speech.Recognition.SpeechDetectedEventArgs>的对象的属性指示识别器在输入流中检测到的语音位置。 有关详细信息, 请<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>参阅<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>和属性以及<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法。  
  
 为<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例是一个控制台应用程序的一部分, 用于为航班选择源和目标城市。 此应用程序识别诸如 "我想要从迈阿密飞到芝加哥" 之类的短语。  该示例使用<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>事件在<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>每次检测到语音时报告。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        Choices cities = new Choices(new string[] {   
          "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I would like to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Create a Grammar object and load it to the recognizer.  
        Grammar g = new Grammar(gb);  
        g.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(g);  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechDetected +=   
          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechDetected event.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine("Speech detected at AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechHypothesized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechHypothesized As EventHandler(Of SpeechHypothesizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechHypothesizedEventArgs ^&gt; ^ SpeechHypothesized;" />
      <MemberSignature Language="F#" Value="member this.SpeechHypothesized : EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " Usage="member this.SpeechHypothesized : System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当识别器已识别可以为语法中多个完整的短语的组件的一个字或多个字时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 当输入不明确时, 共享识别器可以引发此事件。 例如, 对于支持识别 "新游戏" 或 "新游戏" 的语音识别语法, "新游戏" 是一种明确的输入, "新游戏" 是一种不明确的输入。  
  
 为<xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例将识别一些短语, 如 "在爵士乐类别中显示音乐家列表"。 该示例使用<xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>事件在控制台中显示不完整的短语片段, 因为它们被识别。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display the list of");  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the");  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category.");  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechHypothesized +=   
          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine("Speech hypothesized: " + e.Result.Text);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionRejected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognitionRejected As EventHandler(Of SpeechRecognitionRejectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognitionRejectedEventArgs ^&gt; ^ SpeechRecognitionRejected;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognitionRejected : EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " Usage="member this.SpeechRecognitionRejected : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当识别器接收不与它已加载的任何语音识别语法匹配的输入时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果共享识别器确定输入与充分自信的任何已加载语音识别语法匹配, 则会引发此事件。 <xref:System.Speech.Recognition.RecognitionResult>的<xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> 属性包含被<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>拒绝的对象。  
  
 由管理<xref:System.Speech.Recognition.SpeechRecognizer>的共享识别器的置信度阈值与用户配置文件相关联, 并存储在 Windows 注册表中。 对于共享识别器的属性, 应用程序不应将更改写入注册表。  
  
 为<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例将识别一些短语, 如 "在爵士乐类别中显示音乐家列表" 或 "显示唱片集 gospel"。 该示例使用<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>事件的处理程序在控制台中显示一个通知, 以使语音输入不能与语法的内容进行匹配, 从而完全自信地生成成功的识别。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display");  
        mediaMenu.Append("the list of", 0, 1);  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the", 0, 1);  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category", 0, 1);  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechRecognitionRejected +=   
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("Speech input was rejected.");  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognized As EventHandler(Of SpeechRecognizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognizedEventArgs ^&gt; ^ SpeechRecognized;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognized : EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " Usage="member this.SpeechRecognized : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当识别器接收与其语音识别语法匹配的输入时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果识别器决定`SpeechRecognized`完全相信输入与一个已加载和已启用的语音识别语法, 则会引发事件。 的<xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> <xref:System.Speech.Recognition.RecognitionResult>属性包含接受的对象。 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>  
  
 由管理<xref:System.Speech.Recognition.SpeechRecognizer>的共享识别器的置信度阈值与用户配置文件相关联, 并存储在 Windows 注册表中。 对于共享识别器的属性, 应用程序不应将更改写入注册表。  
  
 当识别器接收与某个语法匹配的输入时<xref:System.Speech.Recognition.Grammar> , 该对象可能<xref:System.Speech.Recognition.Grammar.SpeechRecognized>引发事件。 对象的<xref:System.Speech.Recognition.Grammar.SpeechRecognized>事件在语音识别器的<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件发生前引发。 <xref:System.Speech.Recognition.Grammar>  
  
 为<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例是一个控制台应用程序的一部分, 该应用程序加载语音识别语法, 并演示了到共享识别器的语音输入、关联的识别结果和语音识别器引发的相关事件。 如果 Windows 语音识别未运行, 则启动此应用程序也将启动 Windows 语音识别。  
  
 "我想要飞入到迈阿密" 之类的朗读输入将触发<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。 说到 "从休斯顿到芝加哥飞入" 这一<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>短语不会触发事件。  
  
 该示例使用<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件的处理程序显示已成功识别的短语以及它们在控制台中包含的语义。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      </Docs>
    </Member>
    <Member MemberName="State">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerState State { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.RecognizerState State" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property State As RecognizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerState State { System::Speech::Recognition::RecognizerState get(); };" />
      <MemberSignature Language="F#" Value="member this.State : System.Speech.Recognition.RecognizerState" Usage="System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>获取 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 对象的状态。</summary>
        <value><see langword="SpeechRecognizer" /> 对象的状态。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 此只读属性指示位于 Windows `Stopped`中的共享识别器是否处于`Listening`或状态。 有关详细信息，请参见 <xref:System.Speech.Recognition.RecognizerState> 枚举。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="StateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Event StateChanged As EventHandler(Of StateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::StateChangedEventArgs ^&gt; ^ StateChanged;" />
      <MemberSignature Language="F#" Value="member this.StateChanged : EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " Usage="member this.StateChanged : System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>当 Windows“桌面语音技术”识别引擎的运行状态更改时发生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 当 Windows 语音识别的状态更改为<xref:System.Speech.Recognition.RecognizerState.Listening>或<xref:System.Speech.Recognition.RecognizerState.Stopped>状态时, 共享识别器将引发此事件。  
  
 若要在事件发生时获取共享识别器的状态, 请使用<xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>关联<xref:System.Speech.Recognition.StateChangedEventArgs>的的属性。 若要获取共享识别器的当前状态, 请使用识别器<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>的属性。  
  
 为<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件创建委托时, 需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，请将该委托的一个实例添加到事件中。 除非移除了该委托，否则每当发生该事件时就会调用事件处理程序。 有关事件处理程序委托的详细信息, 请参阅[事件和委托](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下面的示例创建一个共享语音识别器, 然后创建两种类型的语法来识别特定单词并接受免费听写。 该示例将所有创建的语法异步加载到识别器。  <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件的处理程序<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>使用方法将 Windows 识别置于 "侦听" 模式。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the SpeechRecognized event.  
      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
      // Add a handler for the StateChanged event.  
      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Create "yesno" grammar.  
      Choices yesChoices = new Choices(new string[] { "yes", "yup", "yah}" });  
      SemanticResultValue yesValue =  
          new SemanticResultValue(yesChoices, (bool)true);  
      Choices noChoices = new Choices(new string[] { "no", "nope", "nah" });  
      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  
      SemanticResultKey yesNoKey =  
          new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
      Grammar yesnoGrammar = new Grammar(yesNoKey);  
      yesnoGrammar.Name = "yesNo";  
  
      // Create "done" grammar.  
      Grammar doneGrammar =  
        new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
      doneGrammar.Name = "Done";  
  
      // Create dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load grammars to the recognizer.  
      recognizer.LoadGrammarAsync(yesnoGrammar);  
      recognizer.LoadGrammarAsync(doneGrammar);  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
     if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
     Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
     string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
      }  
  
      // Add exception handling code here.  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="UnloadAllGrammars">
      <MemberSignature Language="C#" Value="public void UnloadAllGrammars ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadAllGrammars() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      <MemberSignature Language="VB.NET" Value="Public Sub UnloadAllGrammars ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadAllGrammars();" />
      <MemberSignature Language="F#" Value="member this.UnloadAllGrammars : unit -&gt; unit" Usage="speechRecognizer.UnloadAllGrammars " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>从共享识别器卸载所有语音识别语法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果识别器当前正在以异步方式加载语法, 则在卸载该语法之前, 此方法将一直等待, 直到加载了该语法。  
  
 若要卸载特定语法, 请使用<xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="UnloadGrammar">
      <MemberSignature Language="C#" Value="public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.UnloadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.UnloadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">卸载的语法。</param>
        <summary>从共享识别器卸载指定语音识别语法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果识别器正在运行, 则应用程序<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>必须使用在加载、卸载、启用或禁用语法之前暂停语音识别引擎。 若要卸载所有语法, 请<xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>使用方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      </Docs>
    </Member>
  </Members>
</Type>
